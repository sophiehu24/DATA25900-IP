{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7091f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = '/Users/sophiehu/Downloads/folder/*.csv'\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "merged_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv('/Users/sophiehu/Downloads/covidtweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e986e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0,1,2,5,16,85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>covid</th>\n",
       "      <th>191202</th>\n",
       "      <th>162994</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>183233</th>\n",
       "      <th>224870</th>\n",
       "      <th>297595</th>\n",
       "      <th>288947</th>\n",
       "      <th>...</th>\n",
       "      <th>338424</th>\n",
       "      <th>170023</th>\n",
       "      <th>223328</th>\n",
       "      <th>183891</th>\n",
       "      <th>205017</th>\n",
       "      <th>329716</th>\n",
       "      <th>136428</th>\n",
       "      <th>211307</th>\n",
       "      <th>254575</th>\n",
       "      <th>235019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ministro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hari</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624009 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram  counts covid  191202  162994 coronavirus  183233  \\\n",
       "0          covid 19 cases  7888.0   NaN     NaN     NaN         NaN     NaN   \n",
       "1       covid 19 pandemic  7312.0   NaN     NaN     NaN         NaN     NaN   \n",
       "2        covid 19 vaccine  5349.0   NaN     NaN     NaN         NaN     NaN   \n",
       "3       positive covid 19  3544.0   NaN     NaN     NaN         NaN     NaN   \n",
       "4       worse gets better  2854.0   NaN     NaN     NaN         NaN     NaN   \n",
       "...                   ...     ...   ...     ...     ...         ...     ...   \n",
       "624004                NaN     NaN   NaN     NaN     NaN    ministro     NaN   \n",
       "624005                NaN     NaN   NaN     NaN     NaN        hari     NaN   \n",
       "624006                NaN     NaN   NaN     NaN     NaN         sem     NaN   \n",
       "624007                NaN     NaN   NaN     NaN     NaN       worth     NaN   \n",
       "624008                NaN     NaN   NaN     NaN     NaN        lack     NaN   \n",
       "\n",
       "        224870  297595  288947  ...  338424  170023  223328  183891  205017  \\\n",
       "0          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "2          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "3          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "4          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "...        ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "624004     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624005     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624006     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624007     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624008     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "        329716 136428  211307  254575  235019  \n",
       "0          NaN    NaN     NaN     NaN     NaN  \n",
       "1          NaN    NaN     NaN     NaN     NaN  \n",
       "2          NaN    NaN     NaN     NaN     NaN  \n",
       "3          NaN    NaN     NaN     NaN     NaN  \n",
       "4          NaN    NaN     NaN     NaN     NaN  \n",
       "...        ...    ...     ...     ...     ...  \n",
       "624004     NaN    NaN     NaN     NaN  1326.0  \n",
       "624005     NaN    NaN     NaN     NaN  1321.0  \n",
       "624006     NaN    NaN     NaN     NaN  1320.0  \n",
       "624007     NaN    NaN     NaN     NaN  1319.0  \n",
       "624008     NaN    NaN     NaN     NaN  1318.0  \n",
       "\n",
       "[624009 rows x 211 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=pd.read_csv('covidtweets.csv')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "203035c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir('/Users/sophiehu/Downloads/folder'):\n",
    "    # Check if the file ends with '.csv' and contains the string 'April'\n",
    "    if filename.endswith('.csv') and 'top1000' in filename and 'terms' not in filename:\n",
    "        # Read the CSV file into a dataframe and append to the list\n",
    "        df = pd.read_csv('/Users/sophiehu/Downloads/folder/' + filename)\n",
    "        df['title'] = filename[:-4]  # Add a column for the filename\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single dataframe\n",
    "merged_df = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('/Users/sophiehu/Downloads/covid/merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2d3bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416001</th>\n",
       "      <td>san raffaele</td>\n",
       "      <td>295</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416002</th>\n",
       "      <td>read pass</td>\n",
       "      <td>295</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416003</th>\n",
       "      <td>treatment covid</td>\n",
       "      <td>294</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416004</th>\n",
       "      <td>casos sospechosos</td>\n",
       "      <td>294</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416005</th>\n",
       "      <td>bollywood music</td>\n",
       "      <td>294</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416006 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                       title\n",
       "0          covid 19 cases   7888   2020-07-21_top1000bigrams\n",
       "1       covid 19 pandemic   7312   2020-07-21_top1000bigrams\n",
       "2        covid 19 vaccine   5349   2020-07-21_top1000bigrams\n",
       "3       positive covid 19   3544   2020-07-21_top1000bigrams\n",
       "4       worse gets better   2854   2020-07-21_top1000bigrams\n",
       "...                   ...    ...                         ...\n",
       "416001       san raffaele    295  2020-06-01_top1000trigrams\n",
       "416002          read pass    295  2020-06-01_top1000trigrams\n",
       "416003    treatment covid    294  2020-06-01_top1000trigrams\n",
       "416004  casos sospechosos    294  2020-06-01_top1000trigrams\n",
       "416005    bollywood music    294  2020-06-01_top1000trigrams\n",
       "\n",
       "[416006 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf=pd.read_csv('/Users/sophiehu/Downloads/covid/merged.csv')\n",
    "alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59023b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Set the folder path\n",
    "folder_path = \"/Users/sophiehu/Downloads/folder\"\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv') and 'top1000terms' in filename:\n",
    "        csv_file = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Read the CSV file\n",
    "        with open(csv_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            data = list(reader)\n",
    "\n",
    "        # Add headers to the data\n",
    "        data.insert(0, ['gram', 'counts'])\n",
    "\n",
    "        # Write the data back to the CSV file\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f25891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir('/Users/sophiehu/Downloads/folder'):\n",
    "    # Check if the file ends with '.csv' and contains the string 'April'\n",
    "    if filename.endswith('.csv') and 'top1000' in filename:\n",
    "        # Read the CSV file into a dataframe and append to the list\n",
    "        df = pd.read_csv('/Users/sophiehu/Downloads/folder/' + filename)\n",
    "        df['title'] = filename[:-4]  # Add a column for the filename\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single dataframe\n",
    "merged_df = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('/Users/sophiehu/Downloads/covid/merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0fdcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624209</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624210</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624211</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624212</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624213</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624214 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams\n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams\n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams\n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams\n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams\n",
       "...                   ...    ...                        ...\n",
       "624209           ministro   1326    2020-05-20_top1000terms\n",
       "624210               hari   1321    2020-05-20_top1000terms\n",
       "624211                sem   1320    2020-05-20_top1000terms\n",
       "624212              worth   1319    2020-05-20_top1000terms\n",
       "624213               lack   1318    2020-05-20_top1000terms\n",
       "\n",
       "[624214 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "finaldf=pd.read_csv('/Users/sophiehu/Downloads/covid/merged.csv')\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b320b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
