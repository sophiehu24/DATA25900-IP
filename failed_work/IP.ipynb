{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "869d6cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>lang</th>\n",
       "      <th>country_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1212470713338286081</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>20:28:39</td>\n",
       "      <td>ru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212537749485449216</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>00:55:01</td>\n",
       "      <td>ru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1212640596508237824</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>07:43:42</td>\n",
       "      <td>ru</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1212707879872016384</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>12:11:04</td>\n",
       "      <td>ru</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213076662818091008</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>12:36:28</td>\n",
       "      <td>ru</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241091714</th>\n",
       "      <td>1360817167415922689</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>05:04:30</td>\n",
       "      <td>tl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241091715</th>\n",
       "      <td>1360817167629885447</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>05:04:30</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241091716</th>\n",
       "      <td>1360817168821219330</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>05:04:30</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241091717</th>\n",
       "      <td>1360817170507268096</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>05:04:30</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241091718</th>\n",
       "      <td>1360817176043679744</td>\n",
       "      <td>2021-02-14</td>\n",
       "      <td>05:04:32</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241091719 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      tweet_id        date      time lang country_place\n",
       "0          1212470713338286081  2020-01-01  20:28:39   ru           NaN\n",
       "1          1212537749485449216  2020-01-02  00:55:01   ru           NaN\n",
       "2          1212640596508237824  2020-01-02  07:43:42   ru            DE\n",
       "3          1212707879872016384  2020-01-02  12:11:04   ru           NaN\n",
       "4          1213076662818091008  2020-01-03  12:36:28   ru            RU\n",
       "...                        ...         ...       ...  ...           ...\n",
       "241091714  1360817167415922689  2021-02-14  05:04:30   tl           NaN\n",
       "241091715  1360817167629885447  2021-02-14  05:04:30   en           NaN\n",
       "241091716  1360817168821219330  2021-02-14  05:04:30   en           NaN\n",
       "241091717  1360817170507268096  2021-02-14  05:04:30   en           NaN\n",
       "241091718  1360817176043679744  2021-02-14  05:04:32   en           NaN\n",
       "\n",
       "[241091719 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('full_dataset_clean.tsv.gz', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8957ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "!pip install twarc #Twarc\n",
    "!pip install tweepy # Tweepy 3.8.0\n",
    "!pip install argparse #Argparse 3.2\n",
    "!pip install xtract #Xtract 0.1 a3\n",
    "!pip install wget #Wget 3.2\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa1dd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4530779e9b4ba1a5fff165d84b9251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=('all', 'am', 'ar', 'bg', 'bn', 'bo', 'ca', 'ckb', 'cs', 'cy', 'da', 'de', 'dv', 'el', 'en', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import wget\n",
    "import csv\n",
    "import linecache\n",
    "from shutil import copyfile\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset_URL = \"https://github.com/thepanacealab/covid19_twitter/blob/master/dailies/2021-01-20/2021-01-20_clean-dataset.tsv.gz?raw=true\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "#Downloads the dataset (compressed in a GZ format)\n",
    "#!wget dataset_URL -O clean-dataset.tsv.gz\n",
    "wget.download(dataset_URL, out='clean-dataset.tsv.gz')\n",
    "\n",
    "#Unzips the dataset and gets the TSV dataset\n",
    "with gzip.open('clean-dataset.tsv.gz', 'rb') as f_in:\n",
    "    with open('clean-dataset.tsv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "#Deletes the compressed GZ file\n",
    "os.unlink(\"clean-dataset.tsv.gz\")\n",
    "\n",
    "#Gets all possible languages from the dataset\n",
    "df = pd.read_csv('clean-dataset.tsv',sep=\"\\t\")\n",
    "lang_list = df.lang.unique()\n",
    "lang_list= sorted(np.append(lang_list,'all'))\n",
    "lang_picker = widgets.Dropdown(options=lang_list, value=\"all\")\n",
    "lang_picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0418998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "\n",
    "# Authenticate\n",
    "CONSUMER_KEY = \"WLEMGJKOJlo5QQa9feNLFzpl8\" #@param {type:\"string\"}\n",
    "CONSUMER_SECRET_KEY = \"sauCBXzoz0GsV4KMEiod5XsCaTRiJRm3I5TpP3WqwZPClrjWnM\" #@param {type:\"string\"}\n",
    "ACCESS_TOKEN_KEY = \"1653149110407667713-UZk7IXbMT6kIBxBf2eyD6j2zIpNCBg\" #@param {type:\"string\"}\n",
    "ACCESS_TOKEN_SECRET_KEY = \"6Ga14kNssOKmp2oedIwBXBN1Ytz0laroBbFuOarHIk7e1\" #@param {type:\"string\"}\n",
    "\n",
    "#Creates a JSON Files with the API credentials\n",
    "with open('api_keys.json', 'w') as outfile:\n",
    "    json.dump({\n",
    "    \"consumer_key\":CONSUMER_KEY,\n",
    "    \"consumer_secret\":CONSUMER_SECRET_KEY,\n",
    "    \"access_token\":ACCESS_TOKEN_KEY,\n",
    "    \"access_token_secret\": ACCESS_TOKEN_SECRET_KEY\n",
    "     }, outfile)\n",
    "\n",
    "#The lines below are just to test if the twitter credentials are correct\n",
    "# Authenticate\n",
    "#auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET_KEY)\n",
    "\n",
    "#api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "#\t\t\t\t   wait_on_rate_limit_notify=True)\n",
    "\n",
    "#if (not api):\n",
    "#    print (\"Can't Authenticate\")\n",
    "#    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fba968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShowing first 5 tweets from the filtered dataset\u001b[0m\n",
      "['1351757442653294592\\t2021-01-20\\t05:04:23\\ten\\tNULL\\n', '1351757444033069056\\t2021-01-20\\t05:04:23\\ten\\tNULL\\n', '1351757446860083202\\t2021-01-20\\t05:04:24\\ten\\tNULL\\n', '1351757447619375106\\t2021-01-20\\t05:04:24\\ten\\tNULL\\n', '1351757448219140105\\t2021-01-20\\t05:04:24\\ten\\tNULL\\n']\n"
     ]
    }
   ],
   "source": [
    "#Creates a new clean dataset with the specified language (if specified)\n",
    "filtered_language = lang_picker.value\n",
    "\n",
    "#If no language specified, it will get all records from the dataset\n",
    "if filtered_language == \"\":\n",
    "  copyfile('clean-dataset.tsv', 'clean-dataset-filtered.tsv')\n",
    "\n",
    "#If language specified, it will create another tsv file with the filtered records\n",
    "else:\n",
    "  filtered_tw = list()\n",
    "  current_line = 1\n",
    "  with open(\"clean-dataset.tsv\") as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "\n",
    "    if current_line == 1:\n",
    "      filtered_tw.append(linecache.getline(\"clean-dataset.tsv\", current_line))\n",
    "\n",
    "      for line in tsvreader:\n",
    "        if line[3] == filtered_language:\n",
    "          filtered_tw.append(linecache.getline(\"clean-dataset.tsv\", current_line))\n",
    "        current_line += 1\n",
    "\n",
    "  print('\\033[1mShowing first 5 tweets from the filtered dataset\\033[0m')\n",
    "  print(filtered_tw[1:(6 if len(filtered_tw) > 6 else len(filtered_tw))])\n",
    "\n",
    "  with open('clean-dataset-filtered.tsv', 'w') as f_output:\n",
    "      for item in filtered_tw:\n",
    "          f_output.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a4b91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "!wget https://raw.githubusercontent.com/thepanacealab/SMMT/master/data_acquisition/get_metadata.py -O get_metadata.py\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5430b8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your twitter api credentials are valid.\n",
      "hydrated_tweets\n",
      "tab seperated file, using \\t delimiter\n",
      "total ids: 201374\n",
      "metadata collection complete\n",
      "creating master json file\n",
      "currently getting 0 - 100\n",
      "Caught the TweepError exception:\n",
      " [{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]\n",
      "Caught the TweepError exception:\n",
      " [{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]\n",
      "Caught the TweepError exception:\n",
      " [{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]\n",
      "Caught the TweepError exception:\n",
      " [{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]\n",
      "Caught the TweepError exception:\n",
      " [{'message': 'You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, you’ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve', 'code': 453}]\n",
      "^C\n",
      "exception: continuing to zip the file\n",
      "creating ziped master json file\n",
      "creating minimized json master file\n",
      "creating CSV version of minimized json master file\n"
     ]
    }
   ],
   "source": [
    "#from tweepy import TweepError\n",
    "\n",
    "!python get_metadata.py -i clean-dataset-filtered.tsv -o hydrated_tweets -k api_keys.json\n",
    "\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc10d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7091f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = '/Users/sophiehu/Downloads/folder/*.csv'\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "merged_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv('/Users/sophiehu/Downloads/covidtweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e986e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (0,1,2,5,16,85) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>covid</th>\n",
       "      <th>191202</th>\n",
       "      <th>162994</th>\n",
       "      <th>coronavirus</th>\n",
       "      <th>183233</th>\n",
       "      <th>224870</th>\n",
       "      <th>297595</th>\n",
       "      <th>288947</th>\n",
       "      <th>...</th>\n",
       "      <th>338424</th>\n",
       "      <th>170023</th>\n",
       "      <th>223328</th>\n",
       "      <th>183891</th>\n",
       "      <th>205017</th>\n",
       "      <th>329716</th>\n",
       "      <th>136428</th>\n",
       "      <th>211307</th>\n",
       "      <th>254575</th>\n",
       "      <th>235019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ministro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624005</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hari</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624006</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>worth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624008</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624009 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram  counts covid  191202  162994 coronavirus  183233  \\\n",
       "0          covid 19 cases  7888.0   NaN     NaN     NaN         NaN     NaN   \n",
       "1       covid 19 pandemic  7312.0   NaN     NaN     NaN         NaN     NaN   \n",
       "2        covid 19 vaccine  5349.0   NaN     NaN     NaN         NaN     NaN   \n",
       "3       positive covid 19  3544.0   NaN     NaN     NaN         NaN     NaN   \n",
       "4       worse gets better  2854.0   NaN     NaN     NaN         NaN     NaN   \n",
       "...                   ...     ...   ...     ...     ...         ...     ...   \n",
       "624004                NaN     NaN   NaN     NaN     NaN    ministro     NaN   \n",
       "624005                NaN     NaN   NaN     NaN     NaN        hari     NaN   \n",
       "624006                NaN     NaN   NaN     NaN     NaN         sem     NaN   \n",
       "624007                NaN     NaN   NaN     NaN     NaN       worth     NaN   \n",
       "624008                NaN     NaN   NaN     NaN     NaN        lack     NaN   \n",
       "\n",
       "        224870  297595  288947  ...  338424  170023  223328  183891  205017  \\\n",
       "0          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "1          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "2          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "3          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "4          NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "...        ...     ...     ...  ...     ...     ...     ...     ...     ...   \n",
       "624004     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624005     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624006     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624007     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "624008     NaN     NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "        329716 136428  211307  254575  235019  \n",
       "0          NaN    NaN     NaN     NaN     NaN  \n",
       "1          NaN    NaN     NaN     NaN     NaN  \n",
       "2          NaN    NaN     NaN     NaN     NaN  \n",
       "3          NaN    NaN     NaN     NaN     NaN  \n",
       "4          NaN    NaN     NaN     NaN     NaN  \n",
       "...        ...    ...     ...     ...     ...  \n",
       "624004     NaN    NaN     NaN     NaN  1326.0  \n",
       "624005     NaN    NaN     NaN     NaN  1321.0  \n",
       "624006     NaN    NaN     NaN     NaN  1320.0  \n",
       "624007     NaN    NaN     NaN     NaN  1319.0  \n",
       "624008     NaN    NaN     NaN     NaN  1318.0  \n",
       "\n",
       "[624009 rows x 211 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=pd.read_csv('covidtweets.csv')\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "203035c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir('/Users/sophiehu/Downloads/folder'):\n",
    "    # Check if the file ends with '.csv' and contains the string 'April'\n",
    "    if filename.endswith('.csv') and 'top1000' in filename and 'terms' not in filename:\n",
    "        # Read the CSV file into a dataframe and append to the list\n",
    "        df = pd.read_csv('/Users/sophiehu/Downloads/folder/' + filename)\n",
    "        df['title'] = filename[:-4]  # Add a column for the filename\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single dataframe\n",
    "merged_df = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('/Users/sophiehu/Downloads/covid/merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2d3bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416001</th>\n",
       "      <td>san raffaele</td>\n",
       "      <td>295</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416002</th>\n",
       "      <td>read pass</td>\n",
       "      <td>295</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416003</th>\n",
       "      <td>treatment covid</td>\n",
       "      <td>294</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416004</th>\n",
       "      <td>casos sospechosos</td>\n",
       "      <td>294</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416005</th>\n",
       "      <td>bollywood music</td>\n",
       "      <td>294</td>\n",
       "      <td>2020-06-01_top1000trigrams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416006 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                       title\n",
       "0          covid 19 cases   7888   2020-07-21_top1000bigrams\n",
       "1       covid 19 pandemic   7312   2020-07-21_top1000bigrams\n",
       "2        covid 19 vaccine   5349   2020-07-21_top1000bigrams\n",
       "3       positive covid 19   3544   2020-07-21_top1000bigrams\n",
       "4       worse gets better   2854   2020-07-21_top1000bigrams\n",
       "...                   ...    ...                         ...\n",
       "416001       san raffaele    295  2020-06-01_top1000trigrams\n",
       "416002          read pass    295  2020-06-01_top1000trigrams\n",
       "416003    treatment covid    294  2020-06-01_top1000trigrams\n",
       "416004  casos sospechosos    294  2020-06-01_top1000trigrams\n",
       "416005    bollywood music    294  2020-06-01_top1000trigrams\n",
       "\n",
       "[416006 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf=pd.read_csv('/Users/sophiehu/Downloads/covid/merged.csv')\n",
    "alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59023b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Set the folder path\n",
    "folder_path = \"/Users/sophiehu/Downloads/folder\"\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv') and 'top1000terms' in filename:\n",
    "        csv_file = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Read the CSV file\n",
    "        with open(csv_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            data = list(reader)\n",
    "\n",
    "        # Add headers to the data\n",
    "        data.insert(0, ['gram', 'counts'])\n",
    "\n",
    "        # Write the data back to the CSV file\n",
    "        with open(csv_file, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f25891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir('/Users/sophiehu/Downloads/folder'):\n",
    "    # Check if the file ends with '.csv' and contains the string 'April'\n",
    "    if filename.endswith('.csv') and 'top1000' in filename:\n",
    "        # Read the CSV file into a dataframe and append to the list\n",
    "        df = pd.read_csv('/Users/sophiehu/Downloads/folder/' + filename)\n",
    "        df['title'] = filename[:-4]  # Add a column for the filename\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single dataframe\n",
    "merged_df = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "# Write the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('/Users/sophiehu/Downloads/covid/merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0fdcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624209</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624210</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624211</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624212</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624213</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624214 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams\n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams\n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams\n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams\n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams\n",
       "...                   ...    ...                        ...\n",
       "624209           ministro   1326    2020-05-20_top1000terms\n",
       "624210               hari   1321    2020-05-20_top1000terms\n",
       "624211                sem   1320    2020-05-20_top1000terms\n",
       "624212              worth   1319    2020-05-20_top1000terms\n",
       "624213               lack   1318    2020-05-20_top1000terms\n",
       "\n",
       "[624214 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "finaldf=pd.read_csv('/Users/sophiehu/Downloads/covid/merged.csv')\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd28096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55c3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d902d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32287ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textblob_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4904e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_sentiment(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    return analyzer.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8218b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flair_sentiment(text):\n",
    "    classifier = TextClassifier.load('en-sentiment')\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "    return sentence.labels[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ceba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = finaldf.copy()\n",
    "sentiments.dropna(subset=['gram'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f9efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments['textblob_sentiment'] = sentiments['gram'].apply(textblob_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2b3cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624209</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624210</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624211</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624212</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624213</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624209           ministro   1326    2020-05-20_top1000terms   \n",
       "624210               hari   1321    2020-05-20_top1000terms   \n",
       "624211                sem   1320    2020-05-20_top1000terms   \n",
       "624212              worth   1319    2020-05-20_top1000terms   \n",
       "624213               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment  \n",
       "0                 0.000000  \n",
       "1                 0.000000  \n",
       "2                 0.000000  \n",
       "3                 0.227273  \n",
       "4                 0.050000  \n",
       "...                    ...  \n",
       "624209            0.000000  \n",
       "624210            0.000000  \n",
       "624211            0.000000  \n",
       "624212            0.300000  \n",
       "624213            0.000000  \n",
       "\n",
       "[624135 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb5c8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624209</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624210</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624211</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624212</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624213</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624209           ministro   1326    2020-05-20_top1000terms   \n",
       "624210               hari   1321    2020-05-20_top1000terms   \n",
       "624211                sem   1320    2020-05-20_top1000terms   \n",
       "624212              worth   1319    2020-05-20_top1000terms   \n",
       "624213               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \n",
       "0                 0.000000  2020-07-21  top1000bigrams  \n",
       "1                 0.000000  2020-07-21  top1000bigrams  \n",
       "2                 0.000000  2020-07-21  top1000bigrams  \n",
       "3                 0.227273  2020-07-21  top1000bigrams  \n",
       "4                 0.050000  2020-07-21  top1000bigrams  \n",
       "...                    ...         ...             ...  \n",
       "624209            0.000000  2020-05-20    top1000terms  \n",
       "624210            0.000000  2020-05-20    top1000terms  \n",
       "624211            0.000000  2020-05-20    top1000terms  \n",
       "624212            0.300000  2020-05-20    top1000terms  \n",
       "624213            0.000000  2020-05-20    top1000terms  \n",
       "\n",
       "[624135 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the 'gram' column into 'date' and 'category' columns\n",
    "sentiments[['date', 'category']] = sentiments['title'].str.split('_', n=1, expand=True)\n",
    "\n",
    "# format the 'date' column as YYYY-MM-DD\n",
    "sentiments['date'] = pd.to_datetime(sentiments['date']).dt.date.astype(str)\n",
    "\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2055ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624130</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624131</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624132</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624133</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624134</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624130           ministro   1326    2020-05-20_top1000terms   \n",
       "624131               hari   1321    2020-05-20_top1000terms   \n",
       "624132                sem   1320    2020-05-20_top1000terms   \n",
       "624133              worth   1319    2020-05-20_top1000terms   \n",
       "624134               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \\\n",
       "0                 0.000000  2020-07-21  top1000bigrams   \n",
       "1                 0.000000  2020-07-21  top1000bigrams   \n",
       "2                 0.000000  2020-07-21  top1000bigrams   \n",
       "3                 0.227273  2020-07-21  top1000bigrams   \n",
       "4                 0.050000  2020-07-21  top1000bigrams   \n",
       "...                    ...         ...             ...   \n",
       "624130            0.000000  2020-05-20    top1000terms   \n",
       "624131            0.000000  2020-05-20    top1000terms   \n",
       "624132            0.000000  2020-05-20    top1000terms   \n",
       "624133            0.300000  2020-05-20    top1000terms   \n",
       "624134            0.000000  2020-05-20    top1000terms   \n",
       "\n",
       "                                          vader_sentiment  \n",
       "0       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3       {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...  \n",
       "4       {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...  \n",
       "...                                                   ...  \n",
       "624130  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624131  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624132  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624133  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "624134  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "\n",
       "[624135 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "91b2e3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624130</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624131</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624132</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624133</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624134</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624130           ministro   1326    2020-05-20_top1000terms   \n",
       "624131               hari   1321    2020-05-20_top1000terms   \n",
       "624132                sem   1320    2020-05-20_top1000terms   \n",
       "624133              worth   1319    2020-05-20_top1000terms   \n",
       "624134               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \\\n",
       "0                 0.000000  2020-07-21  top1000bigrams   \n",
       "1                 0.000000  2020-07-21  top1000bigrams   \n",
       "2                 0.000000  2020-07-21  top1000bigrams   \n",
       "3                 0.227273  2020-07-21  top1000bigrams   \n",
       "4                 0.050000  2020-07-21  top1000bigrams   \n",
       "...                    ...         ...             ...   \n",
       "624130            0.000000  2020-05-20    top1000terms   \n",
       "624131            0.000000  2020-05-20    top1000terms   \n",
       "624132            0.000000  2020-05-20    top1000terms   \n",
       "624133            0.300000  2020-05-20    top1000terms   \n",
       "624134            0.000000  2020-05-20    top1000terms   \n",
       "\n",
       "                                          vader_sentiment  \n",
       "0       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3       {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...  \n",
       "4       {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...  \n",
       "...                                                   ...  \n",
       "624130  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624131  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624132  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624133  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "624134  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "\n",
       "[624135 rows x 7 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentdf = chunkdf.copy()\n",
    "currentdf\n",
    "# for checkpoint loss purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7074241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            covid 19 cases\n",
       "1         covid 19 pandemic\n",
       "2          covid 19 vaccine\n",
       "3         positive covid 19\n",
       "4         worse gets better\n",
       "                ...        \n",
       "624209             ministro\n",
       "624210                 hari\n",
       "624211                  sem\n",
       "624212                worth\n",
       "624213                 lack\n",
       "Name: gram, Length: 624135, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments['gram'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "975a14b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [2:42:08<00:00,  9.73s/it]   \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "chunks = np.array_split(sentiments, 1000)\n",
    "\n",
    "# Iterate over the chunks using tqdm progress bar\n",
    "for chunk in tqdm(chunks):\n",
    "    # Apply your code to the current chunk\n",
    "    chunk['vader_sentiment'] = chunk['gram'].apply(vader_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "021a88f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gram counts                      title  textblob_sentiment  \\\n",
       "0     covid 19 cases   7888  2020-07-21_top1000bigrams            0.000000   \n",
       "1  covid 19 pandemic   7312  2020-07-21_top1000bigrams            0.000000   \n",
       "2   covid 19 vaccine   5349  2020-07-21_top1000bigrams            0.000000   \n",
       "3  positive covid 19   3544  2020-07-21_top1000bigrams            0.227273   \n",
       "4  worse gets better   2854  2020-07-21_top1000bigrams            0.050000   \n",
       "\n",
       "         date        category  \\\n",
       "0  2020-07-21  top1000bigrams   \n",
       "1  2020-07-21  top1000bigrams   \n",
       "2  2020-07-21  top1000bigrams   \n",
       "3  2020-07-21  top1000bigrams   \n",
       "4  2020-07-21  top1000bigrams   \n",
       "\n",
       "                                     vader_sentiment  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3  {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...  \n",
       "4  {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunkdf = pd.concat(chunks, ignore_index=True)\n",
    "chunkdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c03be8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624209</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624210</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624211</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624212</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624213</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624209           ministro   1326    2020-05-20_top1000terms   \n",
       "624210               hari   1321    2020-05-20_top1000terms   \n",
       "624211                sem   1320    2020-05-20_top1000terms   \n",
       "624212              worth   1319    2020-05-20_top1000terms   \n",
       "624213               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \\\n",
       "0                 0.000000  2020-07-21  top1000bigrams   \n",
       "1                 0.000000  2020-07-21  top1000bigrams   \n",
       "2                 0.000000  2020-07-21  top1000bigrams   \n",
       "3                 0.227273  2020-07-21  top1000bigrams   \n",
       "4                 0.050000  2020-07-21  top1000bigrams   \n",
       "...                    ...         ...             ...   \n",
       "624209            0.000000  2020-05-20    top1000terms   \n",
       "624210            0.000000  2020-05-20    top1000terms   \n",
       "624211            0.000000  2020-05-20    top1000terms   \n",
       "624212            0.300000  2020-05-20    top1000terms   \n",
       "624213            0.000000  2020-05-20    top1000terms   \n",
       "\n",
       "                                          vader_sentiment  \n",
       "0       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3       {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...  \n",
       "4       {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...  \n",
       "...                                                   ...  \n",
       "624209                                                NaN  \n",
       "624210                                                NaN  \n",
       "624211                                                NaN  \n",
       "624212                                                NaN  \n",
       "624213                                                NaN  \n",
       "\n",
       "[624135 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments['vader_sentiment'] = chunkdf['vader_sentiment']\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "628252b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-560989e89c6d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fixing['vader_sentiment'] = fixing['gram'].apply(vader_sentiment)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624135</th>\n",
       "      <td>agree</td>\n",
       "      <td>1416</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624136</th>\n",
       "      <td>run</td>\n",
       "      <td>1416</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624137</th>\n",
       "      <td>saúde</td>\n",
       "      <td>1413</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624138</th>\n",
       "      <td>communities</td>\n",
       "      <td>1412</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624139</th>\n",
       "      <td>noticias</td>\n",
       "      <td>1411</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624209</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624210</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624211</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624212</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624213</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               gram counts                    title  textblob_sentiment  \\\n",
       "624135        agree   1416  2020-05-20_top1000terms                 0.0   \n",
       "624136          run   1416  2020-05-20_top1000terms                 0.0   \n",
       "624137        saúde   1413  2020-05-20_top1000terms                 0.0   \n",
       "624138  communities   1412  2020-05-20_top1000terms                 0.0   \n",
       "624139     noticias   1411  2020-05-20_top1000terms                 0.0   \n",
       "...             ...    ...                      ...                 ...   \n",
       "624209     ministro   1326  2020-05-20_top1000terms                 0.0   \n",
       "624210         hari   1321  2020-05-20_top1000terms                 0.0   \n",
       "624211          sem   1320  2020-05-20_top1000terms                 0.0   \n",
       "624212        worth   1319  2020-05-20_top1000terms                 0.3   \n",
       "624213         lack   1318  2020-05-20_top1000terms                 0.0   \n",
       "\n",
       "              date      category  \\\n",
       "624135  2020-05-20  top1000terms   \n",
       "624136  2020-05-20  top1000terms   \n",
       "624137  2020-05-20  top1000terms   \n",
       "624138  2020-05-20  top1000terms   \n",
       "624139  2020-05-20  top1000terms   \n",
       "...            ...           ...   \n",
       "624209  2020-05-20  top1000terms   \n",
       "624210  2020-05-20  top1000terms   \n",
       "624211  2020-05-20  top1000terms   \n",
       "624212  2020-05-20  top1000terms   \n",
       "624213  2020-05-20  top1000terms   \n",
       "\n",
       "                                          vader_sentiment  \n",
       "624135  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "624136  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624137  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624138  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624139  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "...                                                   ...  \n",
       "624209  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624210  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624211  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624212  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "624213  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "\n",
       "[79 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixing = sentiments[sentiments['vader_sentiment'].isna()] # fix NaNs\n",
    "fixing \n",
    "fixing['vader_sentiment'] = fixing['gram'].apply(vader_sentiment)\n",
    "fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736fc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0bce91c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308114</th>\n",
       "      <td>stop trump</td>\n",
       "      <td>200</td>\n",
       "      <td>2020-10-11_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463653</th>\n",
       "      <td>day spike</td>\n",
       "      <td>372</td>\n",
       "      <td>2020-06-13_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60487</th>\n",
       "      <td>since covid 19</td>\n",
       "      <td>274</td>\n",
       "      <td>2020-04-21_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368437</th>\n",
       "      <td>120 000 people</td>\n",
       "      <td>285</td>\n",
       "      <td>2020-06-21_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>charles highlights coronavirus</td>\n",
       "      <td>114</td>\n",
       "      <td>2020-09-27_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466368</th>\n",
       "      <td>critically ill</td>\n",
       "      <td>765</td>\n",
       "      <td>2020-09-02_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479459</th>\n",
       "      <td>confirmados covid 19</td>\n",
       "      <td>320</td>\n",
       "      <td>2020-05-19_top1000trigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187763</th>\n",
       "      <td>we</td>\n",
       "      <td>1544</td>\n",
       "      <td>2020-06-07_top1000terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233534</th>\n",
       "      <td>patient researchers say</td>\n",
       "      <td>232</td>\n",
       "      <td>2020-08-28_top1000bigrams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521458</th>\n",
       "      <td>contact</td>\n",
       "      <td>3919</td>\n",
       "      <td>2020-06-05_top1000terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  gram counts                       title\n",
       "308114                      stop trump    200  2020-10-11_top1000trigrams\n",
       "463653                       day spike    372  2020-06-13_top1000trigrams\n",
       "60487                   since covid 19    274  2020-04-21_top1000trigrams\n",
       "368437                  120 000 people    285   2020-06-21_top1000bigrams\n",
       "56809   charles highlights coronavirus    114   2020-09-27_top1000bigrams\n",
       "466368                  critically ill    765  2020-09-02_top1000trigrams\n",
       "479459            confirmados covid 19    320  2020-05-19_top1000trigrams\n",
       "187763                              we   1544     2020-06-07_top1000terms\n",
       "233534         patient researchers say    232   2020-08-28_top1000bigrams\n",
       "521458                         contact   3919     2020-06-05_top1000terms"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = finaldf.sample(n=10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "612ae45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:53<02:49, 28.31s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(sample):\n",
    "    # Apply your code to the current chunk\n",
    "    sample['flair_sentiment'] = sample['gram'].apply(flair_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "390ae1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the above progress bar - it would take approx 14 million seconds - 172 days to process the entire dataset.\n",
    "# but when look at actual df it's populated? \n",
    "# unclear if works for full df - maybe skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9193a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>flair_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308114</th>\n",
       "      <td>stop trump</td>\n",
       "      <td>200</td>\n",
       "      <td>2020-10-11_top1000trigrams</td>\n",
       "      <td>0.975517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463653</th>\n",
       "      <td>day spike</td>\n",
       "      <td>372</td>\n",
       "      <td>2020-06-13_top1000trigrams</td>\n",
       "      <td>0.838872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60487</th>\n",
       "      <td>since covid 19</td>\n",
       "      <td>274</td>\n",
       "      <td>2020-04-21_top1000trigrams</td>\n",
       "      <td>0.995612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368437</th>\n",
       "      <td>120 000 people</td>\n",
       "      <td>285</td>\n",
       "      <td>2020-06-21_top1000bigrams</td>\n",
       "      <td>0.985861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56809</th>\n",
       "      <td>charles highlights coronavirus</td>\n",
       "      <td>114</td>\n",
       "      <td>2020-09-27_top1000bigrams</td>\n",
       "      <td>0.993125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466368</th>\n",
       "      <td>critically ill</td>\n",
       "      <td>765</td>\n",
       "      <td>2020-09-02_top1000trigrams</td>\n",
       "      <td>0.999971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479459</th>\n",
       "      <td>confirmados covid 19</td>\n",
       "      <td>320</td>\n",
       "      <td>2020-05-19_top1000trigrams</td>\n",
       "      <td>0.999747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187763</th>\n",
       "      <td>we</td>\n",
       "      <td>1544</td>\n",
       "      <td>2020-06-07_top1000terms</td>\n",
       "      <td>0.981540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233534</th>\n",
       "      <td>patient researchers say</td>\n",
       "      <td>232</td>\n",
       "      <td>2020-08-28_top1000bigrams</td>\n",
       "      <td>0.942363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521458</th>\n",
       "      <td>contact</td>\n",
       "      <td>3919</td>\n",
       "      <td>2020-06-05_top1000terms</td>\n",
       "      <td>0.987091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  gram counts                       title  \\\n",
       "308114                      stop trump    200  2020-10-11_top1000trigrams   \n",
       "463653                       day spike    372  2020-06-13_top1000trigrams   \n",
       "60487                   since covid 19    274  2020-04-21_top1000trigrams   \n",
       "368437                  120 000 people    285   2020-06-21_top1000bigrams   \n",
       "56809   charles highlights coronavirus    114   2020-09-27_top1000bigrams   \n",
       "466368                  critically ill    765  2020-09-02_top1000trigrams   \n",
       "479459            confirmados covid 19    320  2020-05-19_top1000trigrams   \n",
       "187763                              we   1544     2020-06-07_top1000terms   \n",
       "233534         patient researchers say    232   2020-08-28_top1000bigrams   \n",
       "521458                         contact   3919     2020-06-05_top1000terms   \n",
       "\n",
       "        flair_sentiment  \n",
       "308114         0.975517  \n",
       "463653         0.838872  \n",
       "60487          0.995612  \n",
       "368437         0.985861  \n",
       "56809          0.993125  \n",
       "466368         0.999971  \n",
       "479459         0.999747  \n",
       "187763         0.981540  \n",
       "233534         0.942363  \n",
       "521458         0.987091  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ceb332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [1:31:49<1528:58:11, 5509.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-44afa69744d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Apply your code to the current chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mchunk2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flair_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-67fa1e023d46>\u001b[0m in \u001b[0;36mflair_sentiment\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mflair_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TextClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DefaultClassifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifier\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/nn/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_path)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_torch_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mload_torch_state\u001b[0;34m(model_file)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# see https://github.com/zalandoresearch/flair/issues/351\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_big_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/embeddings/transformer.py\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_from_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;31m# copy values from new embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/embeddings/document.py\u001b[0m in \u001b[0;36mcreate_from_state\u001b[0;34m(cls, **state)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# this parameter is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"is_document_embedding\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/embeddings/document.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, layers, layer_mean, is_token_embedding, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mfine_tune\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallows\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtuned\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m         TransformerEmbeddings.__init__(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/flair/embeddings/transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, fine_tune, layers, layer_mean, subtoken_pooling, cls_pooling, is_token_embedding, is_document_embedding, allow_long_sentences, use_context, respect_document_boundaries, context_dropout, saved_config, tokenizer_data, feature_extractor_data, name, force_max_length, needs_manual_ocr, use_context_separator, **kwargs)\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5EncoderModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m         \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_from_config\u001b[0;34m(cls, config, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# restore default dtype if it was modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;31m# Initialize weights and apply final processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_position_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mmodules\u001b[0m \u001b[0mproperly\u001b[0m \u001b[0minitialized\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mweight\u001b[0m \u001b[0minitialization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \"\"\"\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_compatibility_gradient_checkpointing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36minit_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_init_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m             \u001b[0;31m# Initialize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[0;31m# Tie weights should be skipped when not initializing all weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \"\"\"\n\u001b[1;32m    883\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \"\"\"\n\u001b[1;32m    883\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_initialize_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_hf_initialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hf_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36m_init_weights\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over the chunks using tqdm progress bar\n",
    "\n",
    "chunks2 = np.array_split(sentiments, 1000)\n",
    "\n",
    "for chunk2 in tqdm(chunks2):\n",
    "    # Apply your code to the current chunk\n",
    "    chunk2['flair_sentiment'] = chunk2['gram'].apply(flair_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdf['flair_sentiment'] = chunk2df['flair_sentiment']\n",
    "currentdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "add37041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5279.38s/it so flair would take forever :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ac0c6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624130</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624131</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624132</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624133</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624134</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624130           ministro   1326    2020-05-20_top1000terms   \n",
       "624131               hari   1321    2020-05-20_top1000terms   \n",
       "624132                sem   1320    2020-05-20_top1000terms   \n",
       "624133              worth   1319    2020-05-20_top1000terms   \n",
       "624134               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \\\n",
       "0                 0.000000  2020-07-21  top1000bigrams   \n",
       "1                 0.000000  2020-07-21  top1000bigrams   \n",
       "2                 0.000000  2020-07-21  top1000bigrams   \n",
       "3                 0.227273  2020-07-21  top1000bigrams   \n",
       "4                 0.050000  2020-07-21  top1000bigrams   \n",
       "...                    ...         ...             ...   \n",
       "624130            0.000000  2020-05-20    top1000terms   \n",
       "624131            0.000000  2020-05-20    top1000terms   \n",
       "624132            0.000000  2020-05-20    top1000terms   \n",
       "624133            0.300000  2020-05-20    top1000terms   \n",
       "624134            0.000000  2020-05-20    top1000terms   \n",
       "\n",
       "                                          vader_sentiment  \n",
       "0       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3       {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...  \n",
       "4       {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...  \n",
       "...                                                   ...  \n",
       "624130  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624131  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624132  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "624133  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  \n",
       "624134  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "\n",
       "[624135 rows x 7 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed7af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e55b98ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "1         {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "2         {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "3         {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...\n",
       "4         {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...\n",
       "                                ...                        \n",
       "624130    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "624131    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "624132    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
       "624133    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...\n",
       "624134    {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...\n",
       "Name: vader_sentiment, Length: 624135, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentdf['vader_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2ad745cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/624135 [03:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: issubclass() arg 1 must be a class",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-53b9f3b8a584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaderdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Apply your code to the current chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvaderdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvaderdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vader_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4141\u001b[0m             \u001b[0;31m# GH 25959 use pd.array instead of tolist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4142\u001b[0m             \u001b[0;31m# so extension arrays can be used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_expanddim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m             return self._constructor(mapped, index=self.index).__finalize__(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    532\u001b[0m         )\n\u001b[1;32m    533\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         return _list_of_series_to_arrays(\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_of_series_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0maligned_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m     func = _get_take_nd_function(\n\u001b[0m\u001b[1;32m   1757\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_take_nd_function\u001b[0;34m(ndim, arr_dtype, out_dtype, axis, mask_info)\u001b[0m\n\u001b[1;32m   1536\u001b[0m ):\n\u001b[1;32m   1537\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_1d_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;31m# append bit counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_name_includes_bit_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_includes_bit_suffix\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# implied\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_isunsized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;31m# unspecified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \"\"\"\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \"\"\"\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vaderdf = currentdf.copy()\n",
    "\n",
    "for i in tqdm(vaderdf):\n",
    "    # Apply your code to the current chunk\n",
    "    vaderdf[['neg', 'neu', 'pos', 'compound']] = vaderdf['vader_sentiment'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "99284fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510419</th>\n",
       "      <td>covid19 amp</td>\n",
       "      <td>460</td>\n",
       "      <td>2020-08-19_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194395</th>\n",
       "      <td>nothing</td>\n",
       "      <td>2157</td>\n",
       "      <td>2020-09-28_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578036</th>\n",
       "      <td>homenaje víctimas</td>\n",
       "      <td>330</td>\n",
       "      <td>2020-07-17_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050</th>\n",
       "      <td>could</td>\n",
       "      <td>6989</td>\n",
       "      <td>2020-08-08_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106356</th>\n",
       "      <td>redefine relationship</td>\n",
       "      <td>546</td>\n",
       "      <td>2020-09-24_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283381</th>\n",
       "      <td>health minister</td>\n",
       "      <td>406</td>\n",
       "      <td>2020-08-21_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421821</th>\n",
       "      <td>anti</td>\n",
       "      <td>1432</td>\n",
       "      <td>2020-06-21_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404977</th>\n",
       "      <td>coronavirus surge</td>\n",
       "      <td>268</td>\n",
       "      <td>2020-07-04_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29728</th>\n",
       "      <td>dangerous experts rip</td>\n",
       "      <td>198</td>\n",
       "      <td>2020-04-23_top1000trigrams</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468378</th>\n",
       "      <td>24</td>\n",
       "      <td>4296</td>\n",
       "      <td>2020-04-05_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         gram counts                       title  \\\n",
       "510419            covid19 amp    460  2020-08-19_top1000trigrams   \n",
       "194395                nothing   2157     2020-09-28_top1000terms   \n",
       "578036      homenaje víctimas    330  2020-07-17_top1000trigrams   \n",
       "11050                   could   6989     2020-08-08_top1000terms   \n",
       "106356  redefine relationship    546  2020-09-24_top1000trigrams   \n",
       "283381        health minister    406  2020-08-21_top1000trigrams   \n",
       "421821                   anti   1432     2020-06-21_top1000terms   \n",
       "404977      coronavirus surge    268  2020-07-04_top1000trigrams   \n",
       "29728   dangerous experts rip    198  2020-04-23_top1000trigrams   \n",
       "468378                     24   4296     2020-04-05_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date         category  \\\n",
       "510419                 0.0  2020-08-19  top1000trigrams   \n",
       "194395                 0.0  2020-09-28     top1000terms   \n",
       "578036                 0.0  2020-07-17  top1000trigrams   \n",
       "11050                  0.0  2020-08-08     top1000terms   \n",
       "106356                 0.0  2020-09-24  top1000trigrams   \n",
       "283381                 0.0  2020-08-21  top1000trigrams   \n",
       "421821                 0.0  2020-06-21     top1000terms   \n",
       "404977                 0.0  2020-07-04  top1000trigrams   \n",
       "29728                 -0.6  2020-04-23  top1000trigrams   \n",
       "468378                 0.0  2020-04-05     top1000terms   \n",
       "\n",
       "                                          vader_sentiment  \n",
       "510419  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "194395  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "578036  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "11050   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "106356  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "283381  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "421821  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...  \n",
       "404977  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "29728   {'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'comp...  \n",
       "468378  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = currentdf.sample(n=10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "420ace79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:00<00:00, 18.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624130</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624131</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624132</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624133</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624134</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624130           ministro   1326    2020-05-20_top1000terms   \n",
       "624131               hari   1321    2020-05-20_top1000terms   \n",
       "624132                sem   1320    2020-05-20_top1000terms   \n",
       "624133              worth   1319    2020-05-20_top1000terms   \n",
       "624134               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \\\n",
       "0                 0.000000  2020-07-21  top1000bigrams   \n",
       "1                 0.000000  2020-07-21  top1000bigrams   \n",
       "2                 0.000000  2020-07-21  top1000bigrams   \n",
       "3                 0.227273  2020-07-21  top1000bigrams   \n",
       "4                 0.050000  2020-07-21  top1000bigrams   \n",
       "...                    ...         ...             ...   \n",
       "624130            0.000000  2020-05-20    top1000terms   \n",
       "624131            0.000000  2020-05-20    top1000terms   \n",
       "624132            0.000000  2020-05-20    top1000terms   \n",
       "624133            0.300000  2020-05-20    top1000terms   \n",
       "624134            0.000000  2020-05-20    top1000terms   \n",
       "\n",
       "                                          vader_sentiment  neg  neu  pos  \\\n",
       "0       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "1       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "2       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "3       {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...  NaN  NaN  NaN   \n",
       "4       {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...  NaN  NaN  NaN   \n",
       "...                                                   ...  ...  ...  ...   \n",
       "624130  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "624131  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "624132  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "624133  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...  NaN  NaN  NaN   \n",
       "624134  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...  NaN  NaN  NaN   \n",
       "\n",
       "        compound  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "624130       NaN  \n",
       "624131       NaN  \n",
       "624132       NaN  \n",
       "624133       NaN  \n",
       "624134       NaN  \n",
       "\n",
       "[624135 rows x 11 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_components(text):\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "for i in tqdm(sample):\n",
    "    # Apply your code to the current chunk\n",
    "    vaderdf[['neg', 'neu', 'pos', 'compound']] = sample['vader_sentiment'].apply(get_sentiment_components).apply(pd.Series)\n",
    "    \n",
    "vaderdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64c677ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>sentiment_neu</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510419</th>\n",
       "      <td>covid19 amp</td>\n",
       "      <td>460</td>\n",
       "      <td>2020-08-19_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194395</th>\n",
       "      <td>nothing</td>\n",
       "      <td>2157</td>\n",
       "      <td>2020-09-28_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578036</th>\n",
       "      <td>homenaje víctimas</td>\n",
       "      <td>330</td>\n",
       "      <td>2020-07-17_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050</th>\n",
       "      <td>could</td>\n",
       "      <td>6989</td>\n",
       "      <td>2020-08-08_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-08</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106356</th>\n",
       "      <td>redefine relationship</td>\n",
       "      <td>546</td>\n",
       "      <td>2020-09-24_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283381</th>\n",
       "      <td>health minister</td>\n",
       "      <td>406</td>\n",
       "      <td>2020-08-21_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421821</th>\n",
       "      <td>anti</td>\n",
       "      <td>1432</td>\n",
       "      <td>2020-06-21_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404977</th>\n",
       "      <td>coronavirus surge</td>\n",
       "      <td>268</td>\n",
       "      <td>2020-07-04_top1000trigrams</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29728</th>\n",
       "      <td>dangerous experts rip</td>\n",
       "      <td>198</td>\n",
       "      <td>2020-04-23_top1000trigrams</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>top1000trigrams</td>\n",
       "      <td>{'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468378</th>\n",
       "      <td>24</td>\n",
       "      <td>4296</td>\n",
       "      <td>2020-04-05_top1000terms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         gram counts                       title  \\\n",
       "510419            covid19 amp    460  2020-08-19_top1000trigrams   \n",
       "194395                nothing   2157     2020-09-28_top1000terms   \n",
       "578036      homenaje víctimas    330  2020-07-17_top1000trigrams   \n",
       "11050                   could   6989     2020-08-08_top1000terms   \n",
       "106356  redefine relationship    546  2020-09-24_top1000trigrams   \n",
       "283381        health minister    406  2020-08-21_top1000trigrams   \n",
       "421821                   anti   1432     2020-06-21_top1000terms   \n",
       "404977      coronavirus surge    268  2020-07-04_top1000trigrams   \n",
       "29728   dangerous experts rip    198  2020-04-23_top1000trigrams   \n",
       "468378                     24   4296     2020-04-05_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date         category  \\\n",
       "510419                 0.0  2020-08-19  top1000trigrams   \n",
       "194395                 0.0  2020-09-28     top1000terms   \n",
       "578036                 0.0  2020-07-17  top1000trigrams   \n",
       "11050                  0.0  2020-08-08     top1000terms   \n",
       "106356                 0.0  2020-09-24  top1000trigrams   \n",
       "283381                 0.0  2020-08-21  top1000trigrams   \n",
       "421821                 0.0  2020-06-21     top1000terms   \n",
       "404977                 0.0  2020-07-04  top1000trigrams   \n",
       "29728                 -0.6  2020-04-23  top1000trigrams   \n",
       "468378                 0.0  2020-04-05     top1000terms   \n",
       "\n",
       "                                          vader_sentiment  sentiment_neg  \\\n",
       "510419  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "194395  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "578036  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "11050   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "106356  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "283381  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "421821  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...          1.000   \n",
       "404977  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "29728   {'neg': 0.608, 'neu': 0.392, 'pos': 0.0, 'comp...          0.608   \n",
       "468378  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "\n",
       "        sentiment_neu  sentiment_pos  sentiment_compound  \n",
       "510419          1.000            0.0              0.0000  \n",
       "194395          1.000            0.0              0.0000  \n",
       "578036          1.000            0.0              0.0000  \n",
       "11050           1.000            0.0              0.0000  \n",
       "106356          1.000            0.0              0.0000  \n",
       "283381          1.000            0.0              0.0000  \n",
       "421821          0.000            0.0             -0.3182  \n",
       "404977          1.000            0.0              0.0000  \n",
       "29728           0.392            0.0             -0.4767  \n",
       "468378          1.000            0.0              0.0000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments_df = pd.DataFrame(sample['vader_sentiment'].tolist(), index=sample.index)\n",
    "sentiments_df.columns = ['sentiment_' + col for col in sentiments_df.columns]\n",
    "sentiments = pd.concat([sample, sentiments_df], axis=1)\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae711a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/624135 [00:04<100:37:04,  1.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gram</th>\n",
       "      <th>counts</th>\n",
       "      <th>title</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>sentiment_neu</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid 19 cases</td>\n",
       "      <td>7888</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>covid 19 pandemic</td>\n",
       "      <td>7312</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>covid 19 vaccine</td>\n",
       "      <td>5349</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive covid 19</td>\n",
       "      <td>3544</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worse gets better</td>\n",
       "      <td>2854</td>\n",
       "      <td>2020-07-21_top1000bigrams</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>top1000bigrams</td>\n",
       "      <td>{'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624130</th>\n",
       "      <td>ministro</td>\n",
       "      <td>1326</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624131</th>\n",
       "      <td>hari</td>\n",
       "      <td>1321</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624132</th>\n",
       "      <td>sem</td>\n",
       "      <td>1320</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624133</th>\n",
       "      <td>worth</td>\n",
       "      <td>1319</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624134</th>\n",
       "      <td>lack</td>\n",
       "      <td>1318</td>\n",
       "      <td>2020-05-20_top1000terms</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>top1000terms</td>\n",
       "      <td>{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624135 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gram counts                      title  \\\n",
       "0          covid 19 cases   7888  2020-07-21_top1000bigrams   \n",
       "1       covid 19 pandemic   7312  2020-07-21_top1000bigrams   \n",
       "2        covid 19 vaccine   5349  2020-07-21_top1000bigrams   \n",
       "3       positive covid 19   3544  2020-07-21_top1000bigrams   \n",
       "4       worse gets better   2854  2020-07-21_top1000bigrams   \n",
       "...                   ...    ...                        ...   \n",
       "624130           ministro   1326    2020-05-20_top1000terms   \n",
       "624131               hari   1321    2020-05-20_top1000terms   \n",
       "624132                sem   1320    2020-05-20_top1000terms   \n",
       "624133              worth   1319    2020-05-20_top1000terms   \n",
       "624134               lack   1318    2020-05-20_top1000terms   \n",
       "\n",
       "        textblob_sentiment        date        category  \\\n",
       "0                 0.000000  2020-07-21  top1000bigrams   \n",
       "1                 0.000000  2020-07-21  top1000bigrams   \n",
       "2                 0.000000  2020-07-21  top1000bigrams   \n",
       "3                 0.227273  2020-07-21  top1000bigrams   \n",
       "4                 0.050000  2020-07-21  top1000bigrams   \n",
       "...                    ...         ...             ...   \n",
       "624130            0.000000  2020-05-20    top1000terms   \n",
       "624131            0.000000  2020-05-20    top1000terms   \n",
       "624132            0.000000  2020-05-20    top1000terms   \n",
       "624133            0.300000  2020-05-20    top1000terms   \n",
       "624134            0.000000  2020-05-20    top1000terms   \n",
       "\n",
       "                                          vader_sentiment  sentiment_neg  \\\n",
       "0       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "1       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "2       {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "3       {'neg': 0.0, 'neu': 0.357, 'pos': 0.643, 'comp...          0.000   \n",
       "4       {'neg': 0.443, 'neu': 0.143, 'pos': 0.414, 'co...          0.443   \n",
       "...                                                   ...            ...   \n",
       "624130  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "624131  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "624132  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...          0.000   \n",
       "624133  {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound...          0.000   \n",
       "624134  {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound...          1.000   \n",
       "\n",
       "        sentiment_neu  sentiment_pos  sentiment_compound  \n",
       "0               1.000          0.000              0.0000  \n",
       "1               1.000          0.000              0.0000  \n",
       "2               1.000          0.000              0.0000  \n",
       "3               0.357          0.643              0.5574  \n",
       "4               0.143          0.414             -0.0516  \n",
       "...               ...            ...                 ...  \n",
       "624130          1.000          0.000              0.0000  \n",
       "624131          1.000          0.000              0.0000  \n",
       "624132          1.000          0.000              0.0000  \n",
       "624133          0.000          1.000              0.2263  \n",
       "624134          0.000          0.000             -0.3182  \n",
       "\n",
       "[624135 rows x 11 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaderdf = currentdf.copy()\n",
    "\n",
    "for i in tqdm(vaderdf):\n",
    "    # Apply your code to the current chunk\n",
    "    sentiments_df = pd.DataFrame(vaderdf['vader_sentiment'].tolist(), index=vaderdf.index)\n",
    "    sentiments_df.columns = ['sentiment_' + col for col in sentiments_df.columns]\n",
    "sentiments = pd.concat([vaderdf, sentiments_df], axis=1)\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538e749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a547bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do one more sentiment analysis type and then group everything by timing to see when is polarizing\n",
    "# check each type to see if averaging or something else makes the most sense for function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dac72a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5278bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (4.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: requests in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: filelock in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: fsspec in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7db54abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nTFBertForSequenceClassification requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-5f2676f34642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"_from_config\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;31m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"tf\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"torch\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF_IMPORT_ERROR_WITH_PYTORCH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0mchecks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBACKENDS_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nTFBertForSequenceClassification requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c09a4b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (21.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.0.1\n",
      "    Uninstalling pip-21.0.1:\n",
      "      Successfully uninstalled pip-21.0.1\n",
      "Successfully installed pip-23.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b4615f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp38-cp38-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.1/230.1 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow)\n",
      "  Downloading flatbuffers-23.5.8-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting jax>=0.3.15 (from tensorflow)\n",
      "  Downloading jax-0.4.9.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-16.0.0-py2.py3-none-macosx_10_9_x86_64.whl (26.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy<1.24,>=1.22 (from tensorflow)\n",
      "  Downloading numpy-1.23.5-cp38-cp38-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m843.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (20.9)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.23.0-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.54.0-cp38-cp38-macosx_10_10_universal2.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12 (from tensorflow)\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow)\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.13,>=2.12.0 (from tensorflow)\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp38-cp38-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow)\n",
      "  Downloading ml_dtypes-0.1.0-cp38-cp38-macosx_10_9_universal2.whl (317 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.8/317.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.29.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2020.12.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /Users/sophiehu/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.9-py3-none-any.whl size=1477708 sha256=b41b82e0127142794dfd7e90321d1e7201f2c82c3846270ea3152b8d08672c37\n",
      "  Stored in directory: /Users/sophiehu/Library/Caches/pip/wheels/59/43/61/f07ddc82e6b3e002bc38d095ca673476fcd7672538d88d88fe\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, numpy, keras, importlib-metadata, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, pyasn1-modules, opt-einsum, ml-dtypes, markdown, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.2\n",
      "    Uninstalling protobuf-3.20.2:\n",
      "      Successfully uninstalled protobuf-3.20.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.5.8 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 importlib-metadata-6.6.0 jax-0.4.9 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 numpy-1.23.5 opt-einsum-3.3.0 protobuf-4.23.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "934a3d99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nTFBertForSequenceClassification requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-5f2676f34642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"_from_config\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;31m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"tf\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"torch\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF_IMPORT_ERROR_WITH_PYTORCH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0mchecks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBACKENDS_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \nTFBertForSequenceClassification requires the TensorFlow library but it was not found in your environment.\nHowever, we were able to find a PyTorch installation. PyTorch classes do not begin\nwith \"TF\", but are otherwise identically named to our TF classes.\nIf you want to use PyTorch, please use those classes instead!\n\nIf you really do want to use TensorFlow, please follow the instructions on the\ninstallation page https://www.tensorflow.org/install that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "eb3bc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to restart to use package, wouldve lost everything in kernel - started a new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e0edd731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32384bc7d6a741e2b8a2ef01c906b7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb9e7b7c954430fbe805d67f707b256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99cac8058f894f2784b883c47fdfc8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23790d8a1f94a5b8500ade5b9ffe01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4a0b285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.5695649981498718},\n",
       " {'label': 'NEGATIVE', 'score': 0.9992395639419556},\n",
       " {'label': 'NEGATIVE', 'score': 0.9979739785194397},\n",
       " {'label': 'POSITIVE', 'score': 0.8508513569831848},\n",
       " {'label': 'POSITIVE', 'score': 0.9841240048408508},\n",
       " {'label': 'POSITIVE', 'score': 0.9748139977455139},\n",
       " {'label': 'NEGATIVE', 'score': 0.9990823268890381},\n",
       " {'label': 'POSITIVE', 'score': 0.7778550386428833},\n",
       " {'label': 'NEGATIVE', 'score': 0.9885321855545044},\n",
       " {'label': 'POSITIVE', 'score': 0.9911569356918335}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(sample['gram'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b320b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
